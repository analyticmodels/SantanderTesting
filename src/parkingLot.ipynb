{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464638d",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nfrom pathlib import Path\nfrom anthropic import Anthropic\nimport httpx\nimport random\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Initialize Anthropic client with custom httpx client to handle SSL issues\nhttp_client = httpx.Client(verify=False)\nclient = Anthropic(\n    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n    http_client=http_client\n)\n\n# Load base questions using fastparquet engine\nbase_questions_file = Path('../data/baseQuestions.parquet')\ndf_base = pd.read_parquet(base_questions_file, engine='fastparquet')\nbase_questions = df_base['question'].tolist()\n\nprint(f\"Loaded {len(base_questions)} base questions\")\n\n# Generate hallucination-inducing questions\nhallucination_questions = []\ntarget_count = 50\n\n# Sample base questions to work with\nsample_size = min(10, len(base_questions))\nsampled_questions = random.sample(base_questions, sample_size)\n\nfor i, base_question in enumerate(sampled_questions):\n    # Generate multiple variations per base question\n    questions_per_base = (target_count // sample_size) + (1 if i < (target_count % sample_size) else 0)\n    \n    prompt = f\"\"\"Based on this question: \"{base_question}\"\n\nGenerate {questions_per_base} new questions designed to cause LLM hallucinations (not just incorrect answers, but actual hallucinations involving confabulation of plausible-sounding but false details).\n\nUse these techniques:\n- Replace entities with plausible but potentially non-existent names\n- Add specific numerical details (dates, percentages, amounts, limits)\n- Combine real concepts with fabricated specifics\n- Include precise policy/feature details that require exact knowledge\n- Use obscure or ambiguous entity names that sound legitimate\n\nReturn ONLY the questions, one per line, no numbering or extra text.\"\"\"\n\n    response = client.messages.create(\n        model=os.getenv(\"ANTHROPIC_MODEL\", \"claude-sonnet-4-5-20250929\"),\n        max_tokens=2000,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    \n    # Extract questions from response\n    generated = response.content[0].text.strip().split('\\n')\n    generated = [q.strip() for q in generated if q.strip() and not q.strip()[0].isdigit()]\n    \n    hallucination_questions.extend(generated[:questions_per_base])\n    print(f\"Generated {len(generated[:questions_per_base])} questions from base question {i+1}/{len(sampled_questions)}\")\n\n# Ensure we have exactly 50 questions\nhallucination_questions = hallucination_questions[:target_count]\n\n# Create DataFrame and save\ndf_hallucination = pd.DataFrame({'question': hallucination_questions})\noutput_file = Path('../data/hallucinationQuestions.parquet')\ndf_hallucination.to_parquet(output_file, engine='fastparquet', index=False)\n\nprint(f\"\\nTotal hallucination questions generated: {len(hallucination_questions)}\")\nprint(f\"Saved to: {output_file}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0110c4e",
   "metadata": {},
   "outputs": [],
   "source": "# Test API connection\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\nif not api_key:\n    print(\"ANTHROPIC_API_KEY not found in environment\")\nelif api_key.startswith(\"sk-ant-\"):\n    print(f\"API key found: {api_key[:15]}...\")\nelse:\n    print(\"API key found but doesn't match expected format\")\n\n# Test network connectivity\nimport httpx\ntry:\n    response = httpx.get(\"https://api.anthropic.com\", timeout=10.0)\n    print(f\"Can reach Anthropic API (status: {response.status_code})\")\nexcept Exception as e:\n    print(f\"Cannot reach Anthropic API: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f493530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 13852 questions to data/hallucinationQuestions_all.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the parquet file\n",
    "df = pd.read_parquet('../data/hallucinationQuestions_all.parquet')\n",
    "\n",
    "# Export just the questions column to CSV\n",
    "df[['question']].to_csv('../data/hallucinationQuestions_all.csv', index=False)\n",
    "\n",
    "print(f\"Exported {len(df)} questions to data/hallucinationQuestions_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02e4ef1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0  Can I open an account with Openbank if I resid...   \n",
      "2  Is it possible to open a joint Openbank accoun...   \n",
      "3  Does Openbank offer a specific type of account...   \n",
      "5  Can I apply for an Openbank business account w...   \n",
      "6  Is there a separate application process for in...   \n",
      "\n",
      "                                              answer hallucination_score  \\\n",
      "0  OpenBank (also known as Open Bank) is a credit...                FAIL   \n",
      "2  Yes, it is generally possible to open a joint ...                FAIL   \n",
      "3  As of my last update in April 2023, there isn'...                FAIL   \n",
      "5  As of my last update in April 2023, specific p...                FAIL   \n",
      "6  As of my last update in April 2023, I don't ha...                FAIL   \n",
      "\n",
      "                                           reasoning  \\\n",
      "0  {\"REASONING\": ['The CONTEXT does not provide a...   \n",
      "2  {\"REASONING\": ['The context does not provide a...   \n",
      "3  {\"REASONING\": ['The context does not mention a...   \n",
      "5  {\"REASONING\": ['The context does not provide a...   \n",
      "6  {\"REASONING\": ['The QUESTION asks about a spec...   \n",
      "\n",
      "                                   raw_lynx_response  \n",
      "0  {\"REASONING\": ['The CONTEXT does not provide a...  \n",
      "2  {\"REASONING\": ['The context does not provide a...  \n",
      "3  {\"REASONING\": ['The context does not mention a...  \n",
      "5  {\"REASONING\": ['The context does not provide a...  \n",
      "6  {\"REASONING\": ['The QUESTION asks about a spec...  \n",
      "Exported 8353 questions to data/hallucinationQuestions_lynx.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "# Load the parquet file\n",
    "df = pd.read_parquet('../data/hallucinationDetection_lynx.parquet')\n",
    "\n",
    "# Export just the questions column to CSV\n",
    "df = df[df['hallucination_score'] == \"FAIL\"]\n",
    "print(df.head())\n",
    "\n",
    "# Clean questions: remove newlines and ensure proper quoting\n",
    "df['question'] = df['question'].str.replace('\\n', ' ').str.replace('\\r', ' ')\n",
    "df[['question']].to_csv('../data/hallucinationQuestions_lynx.csv', index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "print(f\"Exported {len(df)} questions to data/hallucinationQuestions_lynx.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}